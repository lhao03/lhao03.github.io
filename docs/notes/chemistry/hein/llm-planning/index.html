<!doctype html>
<html lang="en">
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="x-ua-compatible" content="ie=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Lucy H | Notes on LLMs for Planning</title>
  <link rel="stylesheet" href="../../../../css/main.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/default.min.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>
  <!-- and it's easy to individually load additional languages -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/languages/scheme.min.js"></script>
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/base16/onedark.min.css" />
  <script>
    hljs.highlightAll();
  </script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

  <link rel="preconnect" href="https://www.googletagmanager.com" />
  <link rel="preconnect" href="https://www.google-analytics.com" />

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-KDGPVMHC9Q"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag("js", new Date());

    gtag("config", "G-KDGPVMHC9Q");
  </script>

  <!-- basic favicon -->
  <link rel="icon" href="../../../../images/android-chrome-384x384.png" />
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="../../../../images/android-chrome-384x384.png" />
  <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../../../../images/android-chrome-384x384.png" />
  <link rel="apple-touch-icon-precomposed" href="../../../../images/android-chrome-384x384.png" />
</head>

  <body>
    <main role="main">
      <div class="flex-row-col">
        <div>
          <h1>Notes on LLMs for Planning</h1>
          <div>
  
  <div class="header">
    Posted on May 29, 2024
    
  </div>
  <div class="tags">
    
  </div>
  <div class="content">
    <div class="sect1">
<h2 id="_when_prolog_meets_generative_models_a_new_approach_for_managing_knowledge_and_planning_in_robotic_applications">When Prolog meets generative models: a new approach for managing knowledge and planning in robotic applications</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>human knowledge representations are:</p>
</li>
<li>
<p>understandability and explainability</p>
</li>
<li>
<p>scalability</p>
</li>
<li>
<p>usability</p>
</li>
<li>
<p>integrate prolog with deep learning: symbolic/subsymbolic AI</p>
</li>
<li>
<p>can LLM populate a robot-oriented prolog knowledge base?</p>
</li>
<li>
<p>prolog ‚Üí behaviour tree ‚Üí plansys2</p>
</li>
<li>
<p>order matters</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_knowledge_base">knowledge base</h3>
<div class="ulist">
<ul>
<li>
<p>set temperature to 0</p>
</li>
<li>
<p>llm just makes new knowledge base based on examples???</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_large_language_models_as_planning_domain_generators">Large Language Models as Planning Domain Generators</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>larger LLMs exhibit some level of proficiency</p>
</li>
<li>
<p>open-ended output vs. highly structured output</p>
</li>
<li>
<p>LLMs bridge the gap between problem + symbolic representation</p>
</li>
<li>
<p>ground truth: vetted domain specification</p>
</li>
<li>
<p>create high quality reconstructions of PDDL domain from natural language ‚Üí restricted domain eq. to ground truth</p>
</li>
<li>
<p>reference domain is available ‚Üí stronger assumption</p>
</li>
<li>
<p>this paper:</p>
<div class="ulist">
<ul>
<li>
<p>PDDL domain reconstruction from natural language, based on ground truth</p>
</li>
<li>
<p>metrics for evaluating domain quality that don‚Äôt need humans</p>
</li>
<li>
<p>classes of natural language descriptions of PDDL actions to see if including/excluding certain types of informatoin impacts ability to generate domains</p>
</li>
<li>
<p>evaluation of many different models</p>
</li>
<li>
<p>in context learning: consists of an instruction, context examples, query</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_approach">approach</h3>
<div class="ulist">
<ul>
<li>
<p>action-by-action prompting</p>
</li>
<li>
<p>assume predicates and description of these predicates are given to us</p>
</li>
<li>
<p>types of errors encountered: syntax error, semantic error, different domain (no plan found from this domain), heuristically eq</p>
</li>
<li>
<p>results: syntax wise usually correct, heuristically eq (30 ish percent), had semantic issues for predicates, majority of valid generated domains not able to be used for planning (planner couldn
t find anything)</p>
</li>
<li>
<p>LLM+P: natural language description of problem, context example of natural language problem converted to PDDL problem, PDDL domain, plan then fed into LLM to explain</p>
</li>
<li>
<p>end-to-end LLM-DM: domain construction</p>
<div class="ulist">
<ul>
<li>
<p>automated domain construction, human refinement, planning with the domain</p>
</li>
<li>
<p>on an action by action basis, because of context window and potential for corrective feedback ‚Üí more powerful</p>
</li>
<li>
<p>instruction containing PDDL creation task, one/two context examples/ natural language description of domain, natural language description of action, dynamically updated list of predicates based on new actions added</p>
</li>
</ul>
</div>
</li>
<li>
<p>further work: reprompting, fixing mistakes</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_llmp_empowering_large_language_models_with_optimal_planning_proficiency">LLM+P: Empowering Large Language Models with Optimal Planning Proficiency</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>cannot solve long-horizon robot planning problems</p>
</li>
<li>
<p>classical planners: can solve a problem if it is in a certain format</p>
</li>
<li>
<p>LLM+P: given natural language description, output problem description suitable as input to a planner, solves problem using planner, converts output back to natural language and/or connect to robot</p>
</li>
<li>
<p>PDDL as a different language, only generates problem, not the domain</p>
</li>
<li>
<p>LLM provided with minimal example</p>
</li>
<li>
<p>assumptions</p>
<div class="ulist">
<ul>
<li>
<p>robot knows when to trigger LLM+P (not an issue for us)</p>
</li>
<li>
<p>domain PDDL is provided to define actions (but is task agnostic)</p>
</li>
<li>
<p>simple problem description in natural language + corresponding PDDL problem file</p>
</li>
</ul>
</div>
</li>
<li>
<p>context is important, without LLM+P will fail more often</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_learning_general_policies_for_planning_through_gpt_models">Learning General Policies for Planning through GPT Models</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>reasoning capabilities ‚Üí current transformer based models not adequate for planning</p>
</li>
<li>
<p>planGPT, compute effective general policy for planning domain</p>
</li>
<li>
<p>given initial and goal, generate sequence of steps</p>
<div class="ulist">
<ul>
<li>
<p>not what we want</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_integrating_action_knowledge_and_llms_for_task_planning_and_situation_handling_in_open_worlds">Integrating action knowledge and LLMs for task planning and situation handling in open worlds</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>dynamically augment robot‚Äôs action knowledge, grounded to specific domains via action knowledge</p>
</li>
<li>
<p>knowledge from LLMs is domain-independent, robot is domain-dependent</p>
</li>
<li>
<p>LLMs to augment action preconditions/effects</p>
</li>
<li>
<p>LLMs should be able to respond to any situation?</p>
</li>
<li>
<p>COWP vs. ProgPrompt</p>
</li>
<li>
<p>how is "common-sense" extracted?</p>
</li>
<li>
<p>just asking llm questions with template prompts</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_grounded_decoding_guiding_text_generation_with_grounded_models_for_embodied_agents">Grounded Decoding: Guiding Text Generation with Grounded Models for Embodied Agents</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>grounding functions</p>
</li>
<li>
<p>high level instruction and history of executed actions ‚Üí GD probabilistic filtering by selecting tokens with high probability under language model and grounded model</p>
</li>
<li>
<p>obtaining grounding: action-value function, rules, multimodel foundationa models</p>
</li>
<li>
<p>grounded decoding ‚Üí more general/flexible grounding method ‚Üí injects continuous probabilities</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_tree_of_thoughts_deliberate_problem_solving_with_large_language_models">Tree of Thoughts: Deliberate Problem Solving with Large Language Models</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>similar to classical AI planners/solvers</p>
</li>
<li>
<p>humans search through combinatorial problem-space</p>
</li>
<li>
<p>ToT:</p>
</li>
<li>
<p>how to decompose intermediate process into thought steps</p>
</li>
<li>
<p>how to generate potential thoughts from each state</p>
</li>
<li>
<p>how to heuristically evaluate states</p>
</li>
<li>
<p>what search algo to use</p>
</li>
<li>
<p>voting, or value functions</p>
</li>
<li>
<p>BFS or DFS</p>
</li>
<li>
<p>heuristic search</p>
</li>
</ul>
</div>
</div>
</div>

  </div>
  <div class="flex-row link-no-style">
    
    
  </div>
</div>


        </div>
        <div class="sidebar">
  <a href="../../../../"><h2>Lucy Hao</h2></a>
  <a href="../../../../archive"><h3>Thoughts</h3></a>
  <a href="../../../../notes"><h3>Notes</h3></a>
  <a href="../../../../books"><h3>Books</h3></a>
  <a href="../../../../courses"><h3>Courses</h3></a>
  <a href="../../../../cv/cv.pdf"><h3>CV/Resume</h3></a>
</div>

      </div>
    </main>

    <footer>
      <center>
        <p>
          <a href="../../../../archive">archive</a>
          <a href="https://github.com/lhao03" target="_blank">github</a>
          <a href="https://www.linkedin.com/in/lucy-hao/" target="_blank">linkedin</a>
        </p>
      </center>
      Site powered by cats, üç´ and
      <a href="http://jaspervdj.be/hakyll">Hakyll</a>
    </footer>
  </body>
</html>
