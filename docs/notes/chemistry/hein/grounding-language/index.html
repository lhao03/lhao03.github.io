<!doctype html>
<html lang="en">
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="x-ua-compatible" content="ie=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Lucy H | Grounding</title>
  <link rel="stylesheet" href="../../../../css/main.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/default.min.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>
  <!-- and it's easy to individually load additional languages -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/languages/scheme.min.js"></script>
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/base16/onedark.min.css" />
  <script>
    hljs.highlightAll();
  </script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

  <link rel="preconnect" href="https://www.googletagmanager.com" />
  <link rel="preconnect" href="https://www.google-analytics.com" />

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-KDGPVMHC9Q"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag("js", new Date());

    gtag("config", "G-KDGPVMHC9Q");
  </script>

  <!-- basic favicon -->
  <link rel="icon" href="../../../../images/android-chrome-384x384.png" />
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="../../../../images/android-chrome-384x384.png" />
  <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../../../../images/android-chrome-384x384.png" />
  <link rel="apple-touch-icon-precomposed" href="../../../../images/android-chrome-384x384.png" />
</head>

  <body>
    <main role="main">
      <div class="flex-row-col">
        <div>
          <h1>Grounding</h1>
          <div>
  
  <div class="header">
    Posted on May  2, 2024
    
  </div>
  <div class="tags">
    
  </div>
  <div class="content">
    <div class="sect1">
<h2 id="_do_as_i_can_not_as_i_say_grounding_language_in_robotic_affordances">Do As I Can, Not As I Say: Grounding Language in Robotic Affordances</h2>
<div class="sectionbody">
<div class="paragraph">
<p>"With prompt engineering, a LLM may be capable of splitting the high-level instruction into sub-tasks, but it cannot do so without the context of what the robot is capable of given its abilities and the current state of the robot and the environment."</p>
</div>
<div class="ulist">
<ul>
<li>
<p>robot has atomic behaviours</p>
</li>
<li>
<p>system recieves user-provided natural language instruction and set of skills</p>
</li>
<li>
<p>probability given skill makes progress towards completing instruction</p>
</li>
<li>
<p>constraints</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>"Prompt engineering provides examples in the context text (‚Äúprompt‚Äù) for the model that specify the task and the response structure which the model will emulate;"</p>
</div>
<div class="ulist">
<ul>
<li>
<p>value function scores ‚áí should output this score</p>
</li>
<li>
<p>iteratively append skills that increase value function</p>
</li>
<li>
<p>assume optimal set of skills is currently static</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>"The key idea of SayCan is to ground large language models through value functions ‚Äì affordance functions that capture the log likelihood that a particular skill will be able to succeed in the current state."</p>
</div>
<div class="ulist">
<ul>
<li>
<p>language conditioned robotic control policies: instantiate robot with set of skills with policy, value function, short description</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_learning_how_to_ground_a_plan_partial_grounding_in_classical_planning">Learning How to Ground a Plan ‚Äì Partial Grounding in Classical Planning</h2>
<div class="sectionbody">

</div>
</div>
<div class="sect1">
<h2 id="_grounding_natural_language_instructions_to_semantic_goal_representations_for_abstraction_and_generalization">Grounding natural language instructions to semantic goal representations for abstraction and generalization</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>grounding: mapping natural language ‚Üí robot behaviour</p>
</li>
<li>
<p>choice of representation used to capture objective specified by input command</p>
</li>
<li>
<p>markov decision processes</p>
</li>
<li>
<p>abstractions in language map to subgoals ‚Üí decompose generic, abstract commands into modular subgoals ‚Üí robot will be more robsut</p>
</li>
<li>
<p>language grounding model ‚Üí identify linguistic abstraction ‚Üí hierarchical planning ‚Üí efficient robot excecution</p>
</li>
<li>
<p>abstraction ‚Üí key to efficiency</p>
</li>
<li>
<p>mapping to fixed sequences of robot actions ‚Üí unreliable in changing/stochastic environments</p>
</li>
<li>
<p>decouple problem ‚Üí statistical language model to map language and robot goals, reward functions as Markov Decision Process (MDP) ‚Üí arbitrary planner solves MDP</p>
</li>
<li>
<p>novel approaches:</p>
<div class="ulist">
<ul>
<li>
<p>tackle varying granularity of natural language by mapping to reward functions at different levels of abstraction</p>
</li>
<li>
<p>issue of generalization: multistep inference process</p>
</li>
</ul>
</div>
</li>
<li>
<p>decompose representation and infer constiteunt elements</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_related_work">related work</h3>
<div class="ulist">
<ul>
<li>
<p>SHRDLU: handwritten rules, first attempt at agent that can ground language into robot actions</p>
</li>
<li>
<p>language ‚Üí intermediate ‚Üí agent behaviour</p>
<div class="ulist">
<ul>
<li>
<p>lambda calculus, reward functions, constraints for agent to satisfy in the environment</p>
</li>
<li>
<p>learn new grammar rules during course of learning semantic parser, requires a grammar</p>
</li>
</ul>
</div>
</li>
<li>
<p>goal reward function as conjunction of propostional logic functions</p>
</li>
<li>
<p>this work: inference over reward function templates, lifted reward functions ‚Üí specify task while learning environment-specific variables of task undefined</p>
<div class="ulist">
<ul>
<li>
<p>environment binding constraints specify the constraints an object must have to be bound</p>
</li>
<li>
<p>output of grounding model never tired to any particular instantiation of environment</p>
</li>
<li>
<p>given lifted reward function/environment constraint ‚Üí subsequent model can infer environment specific variables ‚Üí pass to a planner</p>
</li>
</ul>
</div>
</li>
<li>
<p>searching an entire search space takes very long ‚Üí decompose planning problem into subtasks ‚Üí temporal abstraction ‚Üí macro actions ‚Üí subgoals via fixed sequence of actions or policy with fixed initial/terminal states</p>
</li>
<li>
<p>bottom up planning vs. top down (322)L</p>
<div class="ulist">
<ul>
<li>
<p>bottom up: reward for each action taken backed up through hierarchy of options</p>
</li>
<li>
<p>top down (AMDP): determine how good a subgoal is before planning to achieve subgoal</p>
</li>
</ul>
</div>
</li>
<li>
<p>natural language as a goal state specifiction + action specifiction</p>
<div class="ulist">
<ul>
<li>
<p>humans mix goal-based commands and action-oriented commands</p>
</li>
</ul>
</div>
</li>
<li>
<p>deep neural networks (LLM??) ‚Üí language grounding</p>
<div class="ulist">
<ul>
<li>
<p>word embeddings and state of the art RNN</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_background">background</h3>
<div class="ulist">
<ul>
<li>
<p>markoc decision process:</p>
<div class="ulist">
<ul>
<li>
<p>five tuple (S, A, T, R, y) set of states, set of actions, transition probability distribution over all possible next states given current state and executed action, R numerical reward earned for particular transition, y is effect time horizon</p>
</li>
</ul>
</div>
</li>
<li>
<p>object-oriented markov decision process</p>
<div class="ulist">
<ul>
<li>
<p>to model robot‚Äôs environment and actions</p>
</li>
<li>
<p>builds upon an MDP by adding sets of object classes and propositional functions</p>
</li>
<li>
<p>predicates as reward functions ‚Üí sufficent semantic representation for grounding language</p>
</li>
<li>
<p>map from natural language to propositional reward functions ‚Üí correctly encapsulate behavoiur indicated by the input command ‚Üí fully specified MDP that can be solved with planning algorithm</p>
</li>
<li>
<p>environment specific grounding module ‚Üí consumes lifted reward functions and low level binding to specific instances</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_semantic_goal_representation">semantic goal representation</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>break natural langauge into task inference and task execution</p>
</li>
<li>
<p>given a language command, find the best r to maximize probability, where r is a lifted propositional function</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_abstraction_in_language">abstraction in language</h3>
<div class="ulist">
<ul>
<li>
<p>high level tasks require long action sequences</p>
</li>
<li>
<p>each level of hierarchy requires own set of reward functions</p>
</li>
<li>
<p>given a natural language command, find corresponding level of abstracttion and lifted reward function that maximizes joint probability</p>
</li>
<li>
<p>language grounding model: infer callable unit, and infer constituent binding arguments ‚Üí given natural command, find callable unit u and binding arguments a that maximuze joint probablity</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_language_grounding_models">language grounding models</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>use of DRAGGN?</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_grounding_module">grounding module</h3>
<div class="ulist">
<ul>
<li>
<p>"For instance, Artzi and Zettle- moyer (2013) present a model for executing lambda-calculus expressions generated by a combinatory categorical grammar (CCG) semantic parser, which grounds ambiguous predicates and nested arguments."</p>
</li>
</ul>
</div>
</div>
</div>
</div>

  </div>
  <div class="flex-row link-no-style">
    
    
  </div>
</div>


        </div>
        <div class="sidebar">
  <a href="../../../../"><h2>Lucy Hao</h2></a>
  <a href="../../../../archive"><h3>Thoughts</h3></a>
  <a href="../../../../notes"><h3>Notes</h3></a>
  <a href="../../../../books"><h3>Books</h3></a>
  <a href="../../../../courses"><h3>Courses</h3></a>
  <a href="../../../../cv/cv.pdf"><h3>CV/Resume</h3></a>
</div>

      </div>
    </main>

    <footer>
      <center>
        <p>
          <a href="../../../../archive">archive</a>
          <a href="https://github.com/lhao03" target="_blank">github</a>
          <a href="https://www.linkedin.com/in/lucy-hao/" target="_blank">linkedin</a>
        </p>
      </center>
      Site powered by cats, üç´ and
      <a href="http://jaspervdj.be/hakyll">Hakyll</a>
    </footer>
  </body>
</html>
