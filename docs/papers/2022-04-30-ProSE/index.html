<!doctype html>
<html lang="en">
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="x-ua-compatible" content="ie=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Lucy H | Paper: ProSE: The Architecture and Design of a Protein Discovery</title>
  <link rel="stylesheet" href="../../css/main.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/default.min.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>
  <!-- and it's easy to individually load additional languages -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/languages/scheme.min.js"></script>
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/base16/onedark.min.css" />
  <script>
    hljs.highlightAll();
  </script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

  <link rel="preconnect" href="https://www.googletagmanager.com" />
  <link rel="preconnect" href="https://www.google-analytics.com" />

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-KDGPVMHC9Q"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag("js", new Date());

    gtag("config", "G-KDGPVMHC9Q");
  </script>

  <!-- basic favicon -->
  <link rel="icon" href="../../images/android-chrome-384x384.png" />
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="../../images/android-chrome-384x384.png" />
  <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../../images/android-chrome-384x384.png" />
  <link rel="apple-touch-icon-precomposed" href="../../images/android-chrome-384x384.png" />
</head>

  <body>
    <main role="main">
      <div class="flex-row-col">
        <div>
          <h2>Paper: ProSE: The Architecture and Design of a Protein Discovery</h2>
          <div>
  
  <div class="header">
    Posted on April 30, 2022
    
  </div>
  <div class="tags">
    
    Tags: architecture, paper
    
  </div>
  <div class="content">
    
<div id="toc" class="toc">Contents:
<ul>
<li><a href="#intro">1 intro</a></li>
<li><a href="#human-language-bert-model-vs.-protein-bert-model">2.1 Human Language BERT Model vs.¬†Protein BERT Model</a></li>
<li><a href="#software-protein-binding-evaluation">2.2 Software Protein Binding Evaluation</a></li>
<li><a href="#profiling-of-the-protein-bert-model">2.3 Profiling of the Protein BERT Model</a></li>
<li><a href="#impact-of-input-sequence-lengths-and-heterogeneity-on-bert-performance">2.4 Impact of Input Sequence Lengths and Heterogeneity on BERT Performance</a></li>
<li><a href="#prose-system">3 Prose System</a></li>
<li><a href="#software-hardware-co-design">3.1 Software-Hardware Co-Design</a></li>
<li><a href="#prose-architecture-and-microarchitecture">3.2 ProSE Architecture and Microarchitecture</a></li>
</ul></div>
<div id="body"><p>Eyes Robson, Ceyu Xu, and Lisa Wu Wills. 2022. ProSE: The Architecture
and Design of a Protein Discovery Engine. In Proceedings of the 27th ACM
International Conference on Architectural Support for Programming Languages
and Operating Systems (ASPLOS ‚Äô22), February 28 ‚Äì March 4, 2022, Lausanne,
Switzerland. ACM, New York, NY, USA, 14 pages.
<a href="https://doi.org/10.1145/3503222.3507722">https://doi.org/10.1145/3503222.3507722</a></p>
<ul>
<li>marries SIMD-style computations with systolic array architectures</li>
</ul>
<h1 id="intro">1 intro</h1>
<ul>
<li>current GPU and TPU systems lack power and are optimized primarily for non-NLP models or NLP models that target human language with short input</li>
<li>current architectures suited for patterns like convolutional filters, not present in Transformers</li>
<li>amino acid is token, protein is input sentence of 300+ tokens</li>
<li>Transformers usually require matrix multiplications with smaller matrice than TPU but larger than GPU</li>
<li>few accelerators target BERT, and they only accelerate a portion of the model</li>
<li>ProSE: multi-threaded <a href="https://en.wikipedia.org/wiki/Heterogeneous_System_Architecture">heterogeneous</a> software-hardware co-designed system that contains collection of heterogeneous systolic arrays and special functions
<ul>
<li>streaming input data using output-stationary systolic array with no provision for specialized intermediate data storage such as local scratchpad</li>
</ul></li>
<li>use accumulator register within each multiply-accumulate unit as intermediate storage to reduce memory requirements</li>
</ul>
<h1 id="human-language-bert-model-vs.-protein-bert-model">2.1 Human Language BERT Model vs.¬†Protein BERT Model</h1>
<ul>
<li>amino acids are 300-2000 tokens in length</li>
</ul>
<h1 id="software-protein-binding-evaluation">2.2 Software Protein Binding Evaluation</h1>
<ul>
<li>geometric binding affinity model OSPREY: high accuracy approach that simulates every atom in detail via costly protein structure information at cost of slow software inference</li>
<li>BERT-style models able to mimic accuracy of OSPREY while excelling at hardware accelerations and also can perform arbitrary downstream tasks (unlike OSPREY)</li>
</ul>
<h1 id="profiling-of-the-protein-bert-model">2.3 Profiling of the Protein BERT Model</h1>
<ul>
<li>percentage of matrix multiplications decreases, while element wise (Matrix Add/Div) and special functions increases</li>
<li>matrix multiplications comprise of 32-52% of total runtime for all input lengths</li>
</ul>
<p>observations
1) matrix multiplications of matrices smaller than TPU provisions, but larger than A100 tensor core
2) element-wise SMID operations/special functions that are usually dependent on result of MatMul or BMM</p>
<ul>
<li>use smaller and varying sized systolic arrays</li>
<li>left-ration-capable systolic arrays =&gt; MatMuls</li>
<li>element-wise SMID operations or special functions in single data slow without need to store and refetch intermediate data</li>
</ul>
<h1 id="impact-of-input-sequence-lengths-and-heterogeneity-on-bert-performance">2.4 Impact of Input Sequence Lengths and Heterogeneity on BERT Performance</h1>
<ul>
<li>homogeneous architecture has much steeper slope as input lengths increases to more than 128 tokens
<ul>
<li>from unnecessary overheads of executing small matrices as inputs on several larger homogeneous systolic arrays and lack of sufficient SIMD units</li>
</ul></li>
</ul>
<h1 id="prose-system">3 Prose System</h1>
<h1 id="software-hardware-co-design">3.1 Software-Hardware Co-Design</h1>
<ul>
<li>identify patterns in protein BERT model and each pattern is performed on the accelerator via pipelined dataflow-esque chaining</li>
</ul>
<p><strong>ProSE Systolic Arrays</strong>
- systolic arrays operate in two modes:
- matmul: move data across PEs top-to-bottom, left-to-right and execute multiply-accumulate per PE<br />
- smid: systolic arrays act as large left column rotates that perform element-wise SIMD-style ALU operations using inputs from the left-most column of the systolic array and the vector register that stores streaming input
- data moves right to left so SIMD ALUs can start executing as soon as left-most column of systolic array has completed its matrix multiplication w/o having to wait for rest of the columns to complete operations</p>
<p><strong>Systolic Array Types</strong>
- divide up systolic arrays into three types, each executing one operation sequence to maximize system efficiency
- M-Type: MatMuls, SIMD ALUs
- G-Type: MatMuls, SIMG ALUs, GELU
- E-Type: MatMuls, SIMD ALU, Exponential functions
- model is separable into Attention, Intermediate, Output sublayers
- for MatMul of varying sizes, smaller systolic arrays suffer less startup and draining costs but take much longer to complete MatMuls
- for SIMD ALU operations: the smaller systolic array, the larger the ratio of available SIMD ALU computation units to PEs</p>
<p><strong>Multithreaded Execution of Heterogeneous Systolic Arrays</strong>
- more threads =&gt; less data-dependency bubbles =&gt; overheard of contention goes up</p>
<h1 id="prose-architecture-and-microarchitecture">3.2 ProSE Architecture and Microarchitecture</h1>
<p><strong>System Overview</strong>
- heterogeneous collection of output-stationary, streaming systolic arrays packaged on one accelerator with host CPU via high-bandwidth external interface</p>
<p><strong>ProSE Operations</strong>
- MatMul
- MulAdd
- MatDiv
- Exp
- GELU</p>
<p><strong>ProSE Processing Element</strong>
- instead of having large local scratchpads or accelerator-attached memory
- output-stationary systolic arrays that uses local multiply-accumulate accumulators as intermediate storage
- streams input continuously from host</p></div>
  </div>
  <div class="flex-row link-no-style">
    
    
  </div>
</div>


        </div>
        <div class="sidebar">
  <a href="../../"><h2>Lucy Hao</h2></a>
  <a href="../../archive"><h3>Thoughts</h3></a>
  <a href="../../papers"><h3>Paper Log</h3></a>
  <a href="../../books"><h3>Books</h3></a>
  <a href="../../cv/cv.pdf"><h3>CV/Resume</h3></a>
</div>

      </div>
    </main>

    <footer>
      <center>
        <p>
          <a href="../../archive">archive</a>
          <a href="https://github.com/lhao03" target="_blank">github</a>
          <a href="https://www.linkedin.com/in/lucy-hao/" target="_blank">linkedin</a>
        </p>
      </center>
      Site powered by cats, üç´ and
      <a href="http://jaspervdj.be/hakyll">Hakyll</a>
    </footer>
  </body>
</html>
