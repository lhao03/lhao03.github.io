---
title: "some papers on planning"
date: 2024-05-14
---

== Towards Plugâ€™n Play Task-Level Autonomy for Robotics Using POMDPs and Generative Models
https://arxiv.org/abs/2207.09713

* bridge gap between "understand what a skill does" and "low-level state variabables"
* what is the impact of the skill on the real world
* lots of integration to tie this all together
* this is done by
** generative skill documentation language, bringing ideas from probabilistic programming languages
** abstraction mapping bridging low level code and AI planning model
** any properly documented skill can be used, providing plug and play experience
** POMDP solver schedules skills

=== introduction
* challenge to address software engineering and execution logic
* writing scripts only address a specific task
* to build autonomous systems that are diverse -> need to keep making scripts for each specific senario
* AI Planners: don't always address partial observability and noisy sensors and rely on ADL (action description languages)
* code based generative model:
** describe planning domain via sampling procedure/simulator that can sample next state given current state/action, correctly
** use code to describe this sampling procedure -> probabilistic programming languages
* robot programmers document their code using more abstract language and use expressive abstraction mapping
** only provide goal specification for each task and system auto genrates needed integration code and controls robot -> autonomous robot operating system
** uses partially observable markov decision processes -> capture stochastic nature of robot actions, noisy and partial sensing

=== planning-based deliberative architectures
* ROSPlan: planning/plan execution architecture for robots generating plans based on PDDL
** single world state and deterministic sensing

=== system overview and concept
* extension of ROSPlan
* documentation:
** GDSL: how the code changes the robot's state and the world's state
** AM: connection between abstract POMDP model and the low level code
***: how to activate the code, how to map abtract parameter values to code-level parameters

== On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)
https://openreview.net/pdf?id=BLsvMLvuhL

== Large Language Models as Planning Domain Generators
https://openreview.net/pdf?id=C88wQIv0aJ

* true potential unfolds when combined with traditional symbolic solvers
** combine generative potential with correctness and precision

* how can LLMs in APS be integrated?
** language translation into PDDL
** plan generation directly from LLM
** model construction: construct or redefine world/domain models
** multi-agent planning: contribute to coordination + creative strategy development
** interactive planning: iterative feedback/interactive planning
** heuristics optimization: optimizing plans through existing plans or heuristic assistance
** brain-inspired planning: act as the coordinator
** tool integration: LLM architectures inspired by neurological/cognitive prcoesses

* APS are highly structured and logical, but lack flexibility and contextual adaptibility, LLMs could fill this gap
** LLMs fail to generate precise, actionable plans
** should combine to create dynamic and context-aware planning approach


=== LLMs
* rule based -> statistical based -> neural network-based models
* RNN and LSTM -> vanishing gradients -> loss of very long sequence contexts
* transformer model: self-attention (SA) mechanisms -> focus on different parts of long input in parallel
** positional encodings: maintain awareness of word/token order
** self-attention: query, key, value system -> contextualize dependencies -> softmax
* CLM: gpt-4: text generation is sequential and dependent on preceding context -> predict next word based on prev word statistically
* MLM: BERT understand directional context, learn forward and backward language dependencies
* Seq2Seq model: transform input into related output -> translation or summarization

=== LLMs in APS
==== language translation
* changing natural language descriptions into PDDL: LLM+P, then translate solution back into natural language
** LLMs can translate PDDL into natural language, but not the other way around because don't understand real world objects and grounding affordances -> neuro-symbolic approach
==== plan generation
* chain-of-symbol, tree of thoughts
* show promise in generating plans within their training set, but show limitations in generalizing out of distribution domains
** casual LLMs: limited due to design, because they generate text based on preciding input
** seq2seq: good within training set data, but bad at generalizing
* integrate imperfect LLM with symbolic planners
==== model construction
* trouble with processing low-level geometricl/shape features
* integrate real world models
==== tool integration
* hallucinate non-existant tools, overuse single tool, strugle with multiple tools

== Planning Domain Simulation: An Interactive System for Plan Visualisation
